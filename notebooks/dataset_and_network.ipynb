{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kanghyun/mambaforge/envs/misalignsr/lib/python3.9/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from basicsr import build_model\n",
    "import misalignSR\n",
    "from basicsr.utils.registry import DATASET_REGISTRY, MODEL_REGISTRY, ARCH_REGISTRY \n",
    "from basicsr.utils.options import yaml_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root path 설정해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path for the root folder is:\n",
      "/home/kanghyun/MisalignSR\n"
     ]
    }
   ],
   "source": [
    "import pyrootutils\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "cwd = Path().resolve()\n",
    "root = pyrootutils.setup_root(\n",
    "    search_from=cwd,\n",
    "    indicator=\".project-root\",\n",
    "    project_root_env_var=True,\n",
    "    dotenv=True,\n",
    "    pythonpath=True,\n",
    "    cwd=True,\n",
    ") # root: root folder path of the directory\n",
    "\n",
    "print(\"Path for the root folder is:\")\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| data_opt: {'dataroot_gt': '/home/kanghyun/MisalignSR/datasets/DIV2K/DIV2K_train_HR_sub',\n",
      "               'dataroot_lq': '/home/kanghyun/MisalignSR/datasets/DIV2K/DIV2K_train_LR_bicubic/X3_sub',\n",
      "               'gt_size': 96,\n",
      "               'io_backend': {'type': 'disk'},\n",
      "               'phase': 'train',\n",
      "               'scale': 3,\n",
      "               'use_hflip': True,\n",
      "               'use_rot': True}\n"
     ]
    }
   ],
   "source": [
    "from icecream import ic # printing function\n",
    "\n",
    "# dataset option\n",
    "data_opt = {}\n",
    "\n",
    "data_opt[\"dataroot_gt\"] = os.path.join(root, \"datasets/DIV2K/DIV2K_train_HR_sub\")\n",
    "data_opt[\"dataroot_lq\"] = os.path.join(root, \"datasets/DIV2K/DIV2K_train_LR_bicubic/X3_sub\")\n",
    "data_opt[\"gt_size\"] = 96\n",
    "data_opt[\"scale\"] = 3\n",
    "data_opt[\"phase\"] = \"train\"\n",
    "\n",
    "data_opt[\"use_hflip\"] = True # Train 시에만 적용\n",
    "data_opt[\"use_rot\"] = True\n",
    "\n",
    "data_opt[\"io_backend\"] = {}\n",
    "data_opt[\"io_backend\"][\"type\"] = \"disk\"\n",
    "\n",
    "_ = ic(data_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DATASET_REGISTRY.get('PairedImageDataset')(data_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 output 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| train_batch.keys(): dict_keys(['lq', 'gt', 'lq_path', 'gt_path'])\n",
      "ic| train_batch[\"lq\"].shape: torch.Size([3, 32, 32])\n",
      "ic| train_batch[\"gt\"].shape: torch.Size([3, 96, 96])\n",
      "ic| train_batch[\"lq_path\"]: '/home/kanghyun/MisalignSR/datasets/DIV2K/DIV2K_train_LR_bicubic/X3_sub/0350_s010.png'\n",
      "ic| train_batch[\"gt_path\"]: '/home/kanghyun/MisalignSR/datasets/DIV2K/DIV2K_train_HR_sub/0350_s010.png'\n"
     ]
    }
   ],
   "source": [
    "ind = 10\n",
    "\n",
    "train_batch = dataset[ind]\n",
    "# lq: low quality, gt: ground truth, lq_path: low quality path, gt_path: ground truth path\n",
    "\n",
    "_ = ic(train_batch.keys())\n",
    "_ = ic(train_batch[\"lq\"].shape)\n",
    "_ = ic(train_batch[\"gt\"].shape)\n",
    "_ = ic(train_batch[\"lq_path\"])\n",
    "_ = ic(train_batch[\"gt_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_opt = {}\n",
    "data_loader_opt[\"batch_size_per_gpu\"] = 16\n",
    "data_loader_opt[\"num_worker_per_gpu\"] = 4\n",
    "data_loader_opt[\"phase\"] = 'train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basicsr import build_dataloader\n",
    "train_loader = build_dataloader(dataset, data_loader_opt, num_gpu=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_g = ARCH_REGISTRY.get('RCAN')(num_in_ch=3, num_out_ch=3, upscale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| train_batch[\"lq\"].shape: torch.Size([3, 32, 32])\n",
      "ic| estY.shape: torch.Size([1, 3, 96, 96])\n",
      "ic| train_batch[\"gt\"].shape: torch.Size([3, 96, 96])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 96, 96])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing in CPU mode\n",
    "estY = network_g(train_batch[\"lq\"])\n",
    "ic(train_batch[\"lq\"].shape)\n",
    "ic(estY.shape)\n",
    "ic(train_batch[\"gt\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 구성하기 \n",
    "[Introduction Link](https://github.com/XPixelGroup/BasicSR/blob/master/docs/introduction.md) 참고\n",
    "\n",
    "Model은 training / validation / testing 을 관장하는 코드 (i.e., setup, feed_data, training step, validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options for the model\n",
    "\n",
    "opt = {}\n",
    "# General settings\n",
    "opt[\"path\"] = {}\n",
    "opt[\"is_train\"] = True\n",
    "opt[\"num_gpu\"] = 1\n",
    "opt[\"dist\"] = False\n",
    "\n",
    "# Network architecture\n",
    "opt[\"network_g\"] = {\"type\": \"RCAN\", \"num_in_ch\": 3, \"num_out_ch\": 3, \"upscale\": 3}\n",
    "\n",
    "# Training settings\n",
    "opt[\"train\"] = {\n",
    "    \"ema_decay\": 0.999, # EMA decay rate\n",
    "    \"optim_g\": {\"type\": \"Adam\", \"lr\": 0.0001, \"weight_decay\": 0, \"betas\": [0.9, 0.99]}, # optimizer\n",
    "    \"scheduler\": {\"type\": \"MultiStepLR\", \"milestones\": [200000], \"gamma\": 0.5}, # learning rate scheduler\n",
    "    \"total_iter\": 300000,\n",
    "    \"warmup_iter\": -1,\n",
    "    \"pixel_opt\": {'type':'L1Loss','loss_weight':1.0, 'reduction':'mean'} # L1 loss\n",
    "}\n",
    "\n",
    "opt['logger'] = {\n",
    "    'print_freq': 100, # print log every 100 iterations\n",
    "    'save_checkpoint_freq': 10000, # save checkpoint every 10000 iterations\n",
    "    'use_tb_logger': False, # use tensorboard logger\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model = MODEL_REGISTRY.get('SRModel')(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kanghyun/BasicSR/basicsr/losses/basic_loss.py:14: UserWarning: Using a target size (torch.Size([3, 96, 96])) that is different to the input size (torch.Size([1, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(pred, target, reduction='none')\n",
      "ic| out.keys(): odict_keys(['lq', 'result', 'gt'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['lq', 'result', 'gt'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 1\n",
    "\n",
    "training_model.feed_data(train_batch)\n",
    "training_model.optimize_parameters(epoch)\n",
    "\n",
    "out = training_model.get_current_visuals()\n",
    "\n",
    "ic(out.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basicsr import tensor2img\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tensor2img(out['result'])\n",
    "lq = tensor2img(out['lq'])\n",
    "gt = tensor2img(out['gt'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
    "axes[0].imshow(lq)\n",
    "axes[1].imshow(result)\n",
    "axes[2].imshow(gt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final end to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 0\n",
    "for epoch in range(10):\n",
    "    for train_batch in train_loader:\n",
    "        training_model.feed_data(train_batch)\n",
    "        training_model.optimize_parameters(iter)\n",
    "        iter += 1\n",
    "        if iter % 1000 == 0:\n",
    "            print('Iter:{}, loss:{}'.format(iter, training_model.get_current_log()['l_pix'])) # current log\n",
    "            out = training_model.get_current_visuals()\n",
    "            result = tensor2img(out['result'], rgb2bgr=False)\n",
    "            lq = tensor2img(out['lq'], rgb2bgr=False)\n",
    "            gt = tensor2img(out['gt'], rgb2bgr=False)\n",
    "\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "            axes[0].imshow(lq)\n",
    "            axes[1].imshow(result)\n",
    "            axes[2].imshow(gt)\n",
    "            fig.suptitle(f\"iter: {iter}\", fontsize=12)\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "            plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MisalignSR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
